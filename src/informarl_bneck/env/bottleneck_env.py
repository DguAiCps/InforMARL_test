"""
Main bottleneck environment for InforMARL
"""
import gymnasium as gym
from gymnasium import spaces
import torch
from torch_geometric.data import Data, Batch
from typing import List, Dict, Any
import numpy as np

from ..utils.types import Agent2D, Landmark2D, Obstacle2D
from ..models import GraphNeuralNetwork, InforMARLAgent
from ..utils.device import get_device, setup_gpu_environment
from .map import create_agents_and_landmarks, create_obstacles
from .physics import execute_action, update_positions, batch_execute_actions_gpu, batch_update_positions_gpu
from .reward import calculate_rewards
from .waypoint_reward import calculate_waypoint_rewards
from .graph_builder import build_graph_observations, batch_build_graph_observations_gpu
from .render import BottleneckRenderer
from .path_planner import update_agent_waypoints, get_waypoint_direction, get_waypoint_distance


class BottleneckInforMARLEnv(gym.Env):
    """2D ë³‘ëª© í™˜ê²½ - InforMARL ê¸°ë°˜"""
    
    def __init__(self, 
                 num_agents: int = 6,
                 agent_radius: float = 0.5,
                 corridor_width: float = 20.0,
                 corridor_height: float = 10.0,
                 bottleneck_width: float = 1.2,
                 bottleneck_position: float = 10.0,
                 sensing_radius: float = 3.0,
                 max_timesteps: int = 300,
                 config: dict = None,  # ğŸ”¥ YAML ì„¤ì •ì„ ë°›ì„ ìˆ˜ ìˆê²Œ
                 gpu_id: int = None,   # ğŸš€ ì„œë²„ GPU ID ì§€ì •
                 force_cpu: bool = False):  # CPU ê°•ì œ ì‚¬ìš©
        
        super().__init__()
        
        # ğŸš€ GPU í™˜ê²½ ì„¤ì •
        setup_gpu_environment()
        self.device = get_device(gpu_id=gpu_id, force_cpu=force_cpu)
        
        # ğŸ”¥ YAML ì„¤ì •ì´ ìˆìœ¼ë©´ ìš°ì„  ì ìš©
        if config is not None:
            self.num_agents = config.get('num_agents', num_agents)
            self.agent_radius = config.get('agent_radius', agent_radius)
            self.corridor_width = config.get('corridor_width', corridor_width)
            self.corridor_height = config.get('corridor_height', corridor_height)
            self.bottleneck_width = config.get('bottleneck_width', bottleneck_width)
            self.bottleneck_position = config.get('bottleneck_position', bottleneck_position)
            self.sensing_radius = config.get('sensing_radius', sensing_radius)
            self.max_timesteps = config.get('max_timesteps', max_timesteps)
            
            # ì„±ëŠ¥ ì„¤ì •
            self.use_gpu_graph = config.get('use_gpu_graph', False)
            self.include_obstacles_in_gnn = config.get('include_obstacles_in_gnn', True)
            force_cpu = config.get('force_cpu', force_cpu)
        else:
            # ê¸°ë³¸ê°’ ì‚¬ìš©
            self.num_agents = num_agents
            self.agent_radius = agent_radius
            self.corridor_width = corridor_width
            self.corridor_height = corridor_height
            self.bottleneck_width = bottleneck_width
            self.bottleneck_position = bottleneck_position
            self.sensing_radius = sensing_radius
            self.max_timesteps = max_timesteps
            self.use_gpu_graph = False  # ê¸°ë³¸ê°’: CPU ê·¸ë˜í”„
            self.include_obstacles_in_gnn = True  # ê¸°ë³¸ê°’: ì¥ì• ë¬¼ í¬í•¨
        
        # í–‰ë™ ê³µê°„: [ìœ„, ì•„ë˜, ì™¼ìª½, ì˜¤ë¥¸ìª½]
        self.action_space = spaces.Discrete(4)
        
        # í™˜ê²½ ìƒíƒœ
        self.agents: List[Agent2D] = []
        self.landmarks: List[Landmark2D] = []
        self.obstacles: List[Obstacle2D] = []
        self.informarl_agents: List[InforMARLAgent] = []
        
        # ê³µìœ  GNNê³¼ ì˜µí‹°ë§ˆì´ì €
        self.shared_gnn = None
        self.gnn_optimizer = None
        
        # ì‹œë®¬ë ˆì´ì…˜ ìƒíƒœ
        self.timestep = 0
        self.success_count = 0
        self.collision_count = 0
        
        # ë Œë”ë§
        self.renderer = BottleneckRenderer()
        
    def reset(self) -> List[Data]:
        """í™˜ê²½ ë¦¬ì…‹"""
        self.timestep = 0
        self.success_count = 0
        self.collision_count = 0
        
        # ë²½ ì—¬ë°± ê³„ì‚°
        obstacle_spacing = (self.agent_radius * 2) / 3
        obstacle_radius = obstacle_spacing / 2
        wall_margin = obstacle_radius * 3
        
        # í™˜ê²½ ê°ì²´ ìƒì„±
        self.agents, self.landmarks = create_agents_and_landmarks(
            self.num_agents, self.corridor_width, self.corridor_height,
            self.agent_radius, wall_margin
        )
        
        self.obstacles = create_obstacles(
            self.corridor_width, self.corridor_height,
            self.bottleneck_position, self.bottleneck_width,
            self.agent_radius
        )
        
        # InforMARL ì—ì´ì „íŠ¸ ìƒì„± (GPU ì‚¬ìš©)
        self.informarl_agents = []
        for i in range(self.num_agents):
            informarl_agent = InforMARLAgent(agent_id=i, device=self.device)
            self.informarl_agents.append(informarl_agent)
        
        # ê³µìœ  GNN ì´ˆê¸°í™” (GPU ì‚¬ìš©)
        if self.shared_gnn is None:
            self.shared_gnn = GraphNeuralNetwork().to(self.device)
            self.gnn_optimizer = torch.optim.Adam(self.shared_gnn.parameters(), lr=0.003)
        
        # ì—ì´ì „íŠ¸ waypoint ì´ˆê¸°í™”
        update_agent_waypoints(
            self.agents, self.landmarks, self.corridor_width, self.corridor_height,
            self.bottleneck_position, self.bottleneck_width
        )
        
        # ê·¸ë˜í”„ ìƒì„± (ì„¤ì •ì— ë”°ë¼ GPU/CPU ì„ íƒ)
        if self.use_gpu_graph:
            try:
                return batch_build_graph_observations_gpu(
                    self.agents, self.landmarks, self.obstacles, self.sensing_radius, 
                    self.device, self.include_obstacles_in_gnn
                )
            except Exception as e:
                print(f"GPU graph building failed in reset, using CPU: {e}")
                return build_graph_observations(
                    self.agents, self.landmarks, self.obstacles, self.sensing_radius,
                    self.include_obstacles_in_gnn
                )
        else:
            return build_graph_observations(
                self.agents, self.landmarks, self.obstacles, self.sensing_radius,
                self.include_obstacles_in_gnn
            )
    
    def step(self, actions: List[int] = None):
        """í™˜ê²½ ìŠ¤í… ì‹¤í–‰"""
        self.timestep += 1
        
        # ê·¸ë˜í”„ ê´€ì¸¡ ìƒì„± (ì„¤ì •ì— ë”°ë¼ GPU/CPU ì„ íƒ)
        if self.use_gpu_graph:
            try:
                graph_obs = batch_build_graph_observations_gpu(
                    self.agents, self.landmarks, self.obstacles, self.sensing_radius, 
                    self.device, self.include_obstacles_in_gnn
                )
            except Exception as e:
                print(f"GPU graph building failed, using CPU: {e}")
                graph_obs = build_graph_observations(
                    self.agents, self.landmarks, self.obstacles, self.sensing_radius,
                    self.include_obstacles_in_gnn
                )
        else:
            graph_obs = build_graph_observations(
                self.agents, self.landmarks, self.obstacles, self.sensing_radius,
                self.include_obstacles_in_gnn
            )
        
        # waypoint ì—…ë°ì´íŠ¸ (ë§¤ ìŠ¤í…)
        update_agent_waypoints(
            self.agents, self.landmarks, self.corridor_width, self.corridor_height,
            self.bottleneck_position, self.bottleneck_width
        )
        
        # í–‰ë™ ì„ íƒ (ë°°ì¹˜ ì²˜ë¦¬)
        if actions is None:
            actions, log_probs, values = self._get_batch_actions(graph_obs, training=True)
        else:
            log_probs = [0.0] * len(actions)
            values = [0.0] * len(actions)
        
        # ğŸš€ GPU ë°°ì¹˜ ë¬¼ë¦¬ ê³„ì‚° (ê¸°ì¡´ CPU ë°©ì‹ë³´ë‹¤ í›¨ì”¬ ë¹ ë¦„)
        try:
            # GPUì—ì„œ í–‰ë™ ì‹¤í–‰ (ë°°ì¹˜)
            new_velocities, new_penalties = batch_execute_actions_gpu(self.agents, actions, self.device)
            
            # í˜ë„í‹° íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸
            for i, agent in enumerate(self.agents):
                agent.collision_penalty_timer = int(new_penalties[i].item())
            
            # GPUì—ì„œ ìœ„ì¹˜ ì—…ë°ì´íŠ¸ (ë°°ì¹˜)
            collision_count = batch_update_positions_gpu(
                self.agents, new_velocities, self.obstacles, 
                self.corridor_width, self.corridor_height,
                self.bottleneck_position, self.bottleneck_width, self.device
            )
        except Exception as e:
            # GPU ì‹¤íŒ¨ ì‹œ CPU ë°±ì—…
            print(f"GPU physics failed, using CPU: {e}")
            for i, action in enumerate(actions):
                execute_action(self.agents[i], action)
            
            collision_count = update_positions(
                self.agents, self.obstacles, self.corridor_width, self.corridor_height,
                self.bottleneck_position, self.bottleneck_width
            )
        self.collision_count += collision_count
        
        # ë³´ìƒ ê³„ì‚° (waypoint ê¸°ë°˜)
        rewards = calculate_waypoint_rewards(self.agents, self.landmarks)
        
        # ì„±ê³µ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
        for agent in self.agents:
            target = self.landmarks[agent.target_id]
            if agent.get_distance_to(target.x, target.y) < target.radius:
                self.success_count += 1
        
        # ê²½í—˜ ì €ì¥
        if actions is not None:
            for i, (action, log_prob, value, reward) in enumerate(zip(actions, log_probs, values, rewards)):
                obs = self._get_local_observation(i)
                experience = {
                    'graph_data': graph_obs[i],
                    'local_obs': torch.tensor(obs, dtype=torch.float32),
                    'action': action,
                    'log_prob': log_prob,
                    'value': value,
                    'reward': reward
                }
                self.informarl_agents[i].store_experience(experience)
        
        # step ëì—ì„œ ìƒˆë¡œìš´ ê´€ì¸¡ ìƒì„± (ì„¤ì •ì— ë”°ë¼ GPU/CPU ì„ íƒ)
        if self.use_gpu_graph:
            try:
                new_obs = batch_build_graph_observations_gpu(
                    self.agents, self.landmarks, self.obstacles, self.sensing_radius, 
                    self.device, self.include_obstacles_in_gnn
                )
            except Exception as e:
                print(f"GPU graph building failed in step end, using CPU: {e}")
                new_obs = build_graph_observations(
                    self.agents, self.landmarks, self.obstacles, self.sensing_radius,
                    self.include_obstacles_in_gnn
                )
        else:
            new_obs = build_graph_observations(
                self.agents, self.landmarks, self.obstacles, self.sensing_radius,
                self.include_obstacles_in_gnn
            )
        done = self._is_done()
        info = self._get_info()
        
        return new_obs, rewards, done, info
    
    def _get_batch_actions(self, graph_observations: List[Data], training: bool = True):
        """ê°œë³„ ê·¸ë˜í”„ ì²˜ë¦¬ - ì„¼ì‹± ë²”ìœ„ ì œí•œ ìœ ì§€í•˜ë©´ì„œ GPU ì‚¬ìš©"""
        device = self.device
        
        actions = []
        log_probs = []
        values = []
        
        # ğŸš€ ë¡œì»¬ ê´€ì¸¡ì„ ë°°ì¹˜ë¡œ GPU ì „ì†¡ (ì—¬ì „íˆ ìµœì í™” ê°€ëŠ¥)
        all_local_obs = []
        for i in range(self.num_agents):
            obs = self._get_local_observation(i)
            all_local_obs.append(obs)
        local_obs_batch = torch.tensor(all_local_obs, dtype=torch.float32).to(device, non_blocking=True)
        
        # ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ëª¨ë“  ê·¸ë˜í”„ë¥¼ í•œ ë²ˆì— GNN í†µê³¼
        batch_graphs = Batch.from_data_list(graph_observations).to(device, non_blocking=True)
        all_embeddings = self.shared_gnn(batch_graphs)
        
        # ê° ê·¸ë˜í”„ë³„ë¡œ ì„ë² ë”© ë¶„ë¦¬
        agent_embeddings = []
        global_embeddings = []
        
        current_idx = 0
        for i in range(self.num_agents):
            graph_size = len(graph_observations[i].x)
            
            # ì´ ê·¸ë˜í”„ì˜ ì„ë² ë”© ì¶”ì¶œ
            graph_embeddings = all_embeddings[current_idx:current_idx + graph_size]
            
            # ì—ì´ì „íŠ¸ ìì‹ ì˜ ì„ë² ë”© (ë³´í†µ ì²« ë²ˆì§¸ ë…¸ë“œ)
            ego_embedding = graph_embeddings[i] if i < len(graph_embeddings) else graph_embeddings[0]
            agent_embeddings.append(ego_embedding)
            
            # ì „ì—­ ì§‘ê³„ë¥¼ ìœ„í•œ ëª¨ë“  ì—ì´ì „íŠ¸ ë…¸ë“œë“¤ì˜ í‰ê· 
            # ì„¼ì‹± ë²”ìœ„ ë‚´ ì—ì´ì „íŠ¸ë“¤ë§Œ í¬í•¨ (ë…¼ë¬¸ì˜ í•µì‹¬!)
            agent_indices = []
            for j, entity_type in enumerate(graph_observations[i].entity_type):
                if entity_type == 0:  # agent íƒ€ì…
                    agent_indices.append(j)
            
            if agent_indices:
                agent_nodes = graph_embeddings[agent_indices]
                global_agg = agent_nodes.mean(dim=0)
            else:
                global_agg = ego_embedding
            
            global_embeddings.append(global_agg)
            
            current_idx += graph_size
        
        # GPUì—ì„œ ë°°ì¹˜ ì²˜ë¦¬
        agent_embeddings_batch = torch.stack(agent_embeddings)
        global_embeddings_batch = torch.stack(global_embeddings)
        
        if training:
            # Criticìœ¼ë¡œ ê°’ í•¨ìˆ˜ ê³„ì‚°
            global_values = self.informarl_agents[0].critic(global_embeddings_batch)
            
            for i, agent in enumerate(self.informarl_agents):
                # Actor: ë¡œì»¬ ê´€ì¸¡ + ì§‘ê³„ ì •ë³´
                local_obs = local_obs_batch[i].unsqueeze(0)
                agg_info = agent_embeddings_batch[i].unsqueeze(0)
                action_probs = agent.actor(local_obs, agg_info)
                
                # í™•ë¥ ì  í–‰ë™ ì„ íƒ
                action_dist = torch.distributions.Categorical(action_probs)
                action = action_dist.sample()
                log_prob = action_dist.log_prob(action)
                
                actions.append(action.item())
                log_probs.append(log_prob.item())
                values.append(global_values[i].item())
        else:
            # í‰ê°€ ì‹œ: Actorë§Œ ì‚¬ìš©
            for i, agent in enumerate(self.informarl_agents):
                local_obs = local_obs_batch[i].unsqueeze(0)
                agg_info = agent_embeddings_batch[i].unsqueeze(0)
                action_probs = agent.actor(local_obs, agg_info)
                
                # ê²°ì •ì  í–‰ë™ ì„ íƒ
                action = torch.argmax(action_probs, dim=1)
                actions.append(action.item())
                log_probs.append(0.0)
                values.append(0.0)
        
        return actions, log_probs, values
    
    def _get_local_observation(self, agent_id: int) -> List[float]:
        """ì—ì´ì „íŠ¸ì˜ ë¡œì»¬ ê´€ì¸¡ (waypoint í¬í•¨)"""
        agent = self.agents[agent_id]
        target = self.landmarks[agent.target_id]
        
        # ê¸°ë³¸ ê´€ì¸¡
        obs = [
            agent.x / self.sensing_radius,    # sensing_radiusë¡œ ì •ê·œí™”ëœ ìœ„ì¹˜
            agent.y / self.sensing_radius,
            agent.vx / agent.max_speed,       # ì •ê·œí™”ëœ ì†ë„
            agent.vy / agent.max_speed,
            (target.x - agent.x) / self.sensing_radius,  # ìƒëŒ€ ëª©í‘œ ìœ„ì¹˜
            (target.y - agent.y) / self.sensing_radius
        ]
        
        # waypoint ì •ë³´ ì¶”ê°€
        waypoint_direction = get_waypoint_direction(agent)
        waypoint_distance = get_waypoint_distance(agent)
        
        obs.extend([
            waypoint_direction[0],  # waypoint ë°©í–¥ x
            waypoint_direction[1],  # waypoint ë°©í–¥ y  
            waypoint_distance / self.sensing_radius  # ì •ê·œí™”ëœ waypoint ê±°ë¦¬
        ])
        
        return obs
    
    def _is_done(self) -> bool:
        """ì¢…ë£Œ ì¡°ê±´"""
        if self.timestep >= self.max_timesteps:
            return True
        
        # ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ëª©í‘œ ë„ë‹¬
        for agent in self.agents:
            target = self.landmarks[agent.target_id]
            if agent.get_distance_to(target.x, target.y) >= target.radius:
                return False
        return True
    
    def _get_info(self) -> Dict[str, Any]:
        """ì •ë³´ ë°˜í™˜"""
        return {
            "timestep": self.timestep,
            "success_count": self.success_count,
            "collision_count": self.collision_count,
            "success_rate": self.success_count / max(1, self.num_agents),
            "avg_time_ratio": self.timestep / self.max_timesteps
        }
    
    def render(self, mode='human'):
        """í™˜ê²½ ë Œë”ë§"""
        self.renderer.render(
            self.agents, self.landmarks, self.obstacles,
            self.corridor_width, self.corridor_height,
            self.bottleneck_position, self.bottleneck_width,
            self.timestep, self.success_count, self.collision_count
        )